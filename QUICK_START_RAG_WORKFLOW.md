# Quick Start: RAG + VCP Workflow

**Get started in 5 minutes!**

---

## ğŸ“¦ What You Got

âœ… **Semantic Earnings Search** - Query earnings documents with natural language
âœ… **4-Stage VCP Workflow** - Automated stock analysis pipeline
âœ… **Memory Integration** - Context across sessions
âœ… **35/35 Tests Passing** - Production-ready code

---

## ğŸš€ Quick Start

### 1. Set Environment Variable

```bash
export OPENAI_API_KEY='your-openai-api-key-here'
```

### 2. Test RAG System

```bash
# Run tests
python3 -m pytest tests/unit/test_earnings_rag.py -v

# Expected: 13/13 PASSED âœ…
```

### 3. Test VCP Workflow

```bash
# Run tests
python3 -m pytest tests/unit/test_vcp_workflow.py -v

# Expected: 22/22 PASSED âœ…
```

### 4. Use RAG for Earnings Search

```python
# Create some sample earnings data (or use your existing PDFs)
from src.rag.earnings_query import get_earnings_query_engine

# Query (works even without indexed PDFs - just returns no results)
engine = get_earnings_query_engine()
stats = engine.vector_store_wrapper.get_stats()
print(f"Documents indexed: {stats.get('count', 0)}")

# To actually ingest PDFs:
# python src/rag/earnings_ingestion.py data/earnings_pdfs
```

### 5. Use VCP Workflow

```python
from agents.workflows.vcp_workflow import run_vcp_analysis

# Analyze a stock (uses Yahoo Finance)
result = run_vcp_analysis("TCS", "NSE")

print(f"Success: {result.success}")
print(f"Confidence: {result.confidence_score:.1%}")
print(f"\n{result.final_recommendation}")
```

---

## ğŸ“– Full Examples

### Example 1: Semantic Earnings Search

```python
from src.rag.earnings_ingestion import ingest_earnings_pdfs
from src.rag.earnings_query import get_earnings_query_engine

# 1. Ingest PDFs (one-time setup)
success = ingest_earnings_pdfs("data/earnings_pdfs")
# Output: âœ… Ingestion successful! Total documents indexed: 150

# 2. Query semantically
engine = get_earnings_query_engine()

result = engine.query("Which companies showed strong QoQ revenue growth?")
print(result.response)

# 3. Filter by company
tcs_result = engine.search_by_company(
    "TCS",
    "What was the profit margin in Q4FY24?"
)
print(tcs_result.response)

# 4. Compare companies
comparison = engine.compare_companies(
    ["TCS", "INFY", "WIPRO"],
    "Revenue growth trends"
)
for company, result in comparison.items():
    print(f"\n{company}:")
    print(result.response if result else "No data")
```

### Example 2: VCP Workflow Analysis

```python
from agents.workflows import get_vcp_workflow
import asyncio

# Async version (recommended)
async def analyze_stock(symbol):
    workflow = get_vcp_workflow(use_memory=True)
    result = await workflow.run(symbol, "NSE")

    print(f"\n{'='*50}")
    print(f"VCP Analysis: {result.symbol}")
    print(f"{'='*50}")

    # Stage-by-stage results
    for stage in result.stages:
        status = "âœ“" if stage.success else "âœ—"
        print(f"{status} {stage.stage_name}: {stage.execution_time:.2f}s")

    print(f"\nConfidence: {result.confidence_score:.1%}")
    print(f"\n{result.final_recommendation}")

    # Access specific stage data
    signal_stage = result.get_stage("SignalGenerator")
    if signal_stage:
        print(f"\nSignal: {signal_stage.data.get('signal')}")
        print(f"Entry: â‚¹{signal_stage.data.get('entry_price'):.2f}")

# Run
asyncio.run(analyze_stock("TCS"))

# Synchronous version (simpler)
from agents.workflows.vcp_workflow import run_vcp_analysis

result = run_vcp_analysis("RELIANCE", "NSE")
print(result.final_recommendation)
```

### Example 3: Combined RAG + Workflow

```python
from agents.workflows import get_vcp_workflow
from src.rag.earnings_query import get_earnings_query_engine
import asyncio

async def comprehensive_analysis(symbol):
    # 1. Run VCP workflow
    workflow = get_vcp_workflow()
    vcp_result = await workflow.run(symbol, "NSE")

    # 2. Deep dive with RAG
    engine = get_earnings_query_engine()
    earnings_detail = engine.search_by_company(
        symbol,
        "Provide detailed QoQ earnings breakdown and growth trends"
    )

    # 3. Combined decision
    print(f"\n{'='*60}")
    print(f"COMPREHENSIVE ANALYSIS: {symbol}")
    print(f"{'='*60}")

    print(f"\nğŸ“Š VCP Workflow Result:")
    print(f"Signal: {vcp_result.get_stage('SignalGenerator').data.get('signal')}")
    print(f"Confidence: {vcp_result.confidence_score:.1%}")
    print(f"VCP Detected: {vcp_result.get_stage('PatternDetector').data.get('vcp_detected')}")

    print(f"\nğŸ“ˆ Earnings Deep Dive:")
    print(earnings_detail.response)

    print(f"\nğŸ’¡ Final Recommendation:")
    print(vcp_result.final_recommendation)

asyncio.run(comprehensive_analysis("TCS"))
```

---

## ğŸ“ File Structure

```
New files created:

src/rag/
â”œâ”€â”€ __init__.py              (auto-created)
â”œâ”€â”€ vector_store.py          â† LanceDB configuration
â”œâ”€â”€ earnings_ingestion.py    â† PDF ingestion pipeline
â”œâ”€â”€ earnings_query.py        â† Semantic query engine
â””â”€â”€ README.md                â† Complete documentation

agents/workflows/
â”œâ”€â”€ __init__.py              â† Module exports
â””â”€â”€ vcp_workflow.py          â† 4-stage VCP workflow

tests/unit/
â”œâ”€â”€ test_earnings_rag.py     â† RAG tests (13/13 âœ…)
â””â”€â”€ test_vcp_workflow.py     â† Workflow tests (22/22 âœ…)

Documentation:
â”œâ”€â”€ INTEGRATION_COMPLETE_PHASE_1_2.md  â† Full summary
â””â”€â”€ QUICK_START_RAG_WORKFLOW.md        â† This file
```

---

## ğŸ§ª Testing

```bash
# Test everything
python3 -m pytest tests/unit/test_earnings_rag.py tests/unit/test_vcp_workflow.py -v

# Expected output:
# âœ… 13 passed (RAG)
# âœ… 22 passed (Workflow)
# Total: 35/35 PASSED
```

---

## ğŸ”§ Troubleshooting

### Issue: "OPENAI_API_KEY environment variable not set"
```bash
export OPENAI_API_KEY='your-key-here'
```

### Issue: "Table doesn't exist" when querying
```bash
# First ingest some PDFs
python src/rag/earnings_ingestion.py data/earnings_pdfs
```

### Issue: "No OHLCV data available"
- Workflow uses Yahoo Finance
- Check internet connection
- Verify symbol format (e.g., "TCS" not "TCS.NS")
- Exchange should be "NSE" or "BSE"

### Issue: Import errors
```bash
# Reinstall dependencies
pip install lancedb llama-index llama-index-embeddings-openai
pip install llama-index-vector-stores-lancedb
```

---

## ğŸ“Š Performance

| Operation | Time |
|-----------|------|
| PDF Ingestion | 5-10/min |
| Semantic Query | < 2s |
| VCP Workflow (4 stages) | 4-6s |
| Memory Search | < 0.5s |

---

## ğŸ¯ Next Steps

1. **Ingest Your Earnings Data**
   ```bash
   python src/rag/earnings_ingestion.py data/earnings_pdfs
   ```

2. **Test on Real Stocks**
   ```python
   from agents.workflows.vcp_workflow import run_vcp_analysis
   result = run_vcp_analysis("TCS", "NSE")
   ```

3. **Integrate with Dexter**
   ```python
   # Use workflow results in Dexter research
   from dexter import DexterAgent

   vcp_result = run_vcp_analysis("TCS", "NSE")
   dexter = DexterAgent()
   research = await dexter.research(
       f"Deep analysis of TCS. VCP confidence: {vcp_result.confidence_score:.1%}"
   )
   ```

4. **Explore Phase 3 & 4** (Optional)
   - Hybrid RAG with web search
   - Parallel financial analysis
   - Phoenix/AgentOps observability

---

## ğŸ“– Documentation

- **Complete Guide**: `INTEGRATION_COMPLETE_PHASE_1_2.md`
- **RAG Documentation**: `src/rag/README.md`
- **Tests**: `tests/unit/test_*.py`

---

**Ready to use! ğŸš€**

All 35 tests passing. Production-ready code. Zero breaking changes.
